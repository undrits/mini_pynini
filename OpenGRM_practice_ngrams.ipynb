{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NGRAM LM\n",
    "\n",
    "#open txt file and tokenize it and save into .tok file\n",
    "python word_tokenize.py news_small.txt > news_small.tok\n",
    "\n",
    "#create a symbol table for all tokens\n",
    "#Usage: ngramsymbols [--options] [in.txt [out.txt]]\n",
    "ngramsymbols news_small.tok news_small.sym\n",
    "\n",
    "#farcompilestrings = compile a set of strings as FST and save it into .far (FSA archive)\n",
    "#Usage:farcompilestrings [in1.txt [[in2.txt ...] out.far]]\n",
    "farcompilestrings --fst_type=compact --symbols=news_small.sym --keep_symbols news_small.tok news_small.far\n",
    "\n",
    "#info about the .far file\n",
    "farinfo news_small.far\n",
    "\n",
    "#counts n-grams from an FSA archive and output a count FST\n",
    "#Usage: ngramcount [--options] [in.far [out.fst]]\n",
    "#order=3 == trigram\n",
    "ngramcount --order=3 news_small.far news_small.cnt\n",
    "\n",
    "#make a LM using a smoothing Kneser_new method\n",
    "ngrammake --method=kneser_ney news_small.cnt news_small.lm\n",
    "\n",
    "#LM info\n",
    "fstinfo news_small.lm\n",
    "ngraminfo news_small.lm\n",
    "\n",
    "#Perplexity of the LM\n",
    "ngramperplexity news_small.lm news_small.far\n",
    "\n",
    "#Shrink LM to only 10k most frequent ones\n",
    "ngramshrink --method=relative_entropy --target_number_of_ngrams=10000 news_small.lm news_small.shrunk.lm\n",
    "\n",
    "#Perplexity of the shrunk LM \n",
    "#much higher than before\n",
    "ngramperplexity news_small.shrunk.lm news_small.far\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAR MODEL\n",
    "\n",
    "#compile a character model out of the same txt file\n",
    "farcompilestrings --far_type=compact_string --token_type=byte news_small.txt news_small.char.far\n",
    "\n",
    "farinfo news_small.char.far \n",
    "\n",
    "#newer version option: doesn't require symbols, straight to counts\n",
    "#DOESNT WORK DOWNSTREAM FOR PERPLEXITY\n",
    "ngramcount --require_symbols=false --order=6 news_small.char.far news_small.char.cnt\n",
    "\n",
    "#instead\n",
    "ngramsymbols news_small.txt news_small.sym\n",
    "farcompilestrings --far_type=compact_string --token_type=byte --symbols=news_small.sym --keep_symbols news_small.txt news_small.char.far\n",
    "ngramcount --order=6 news_small.char.far news_small.char.cnt\n",
    "\n",
    "#make character n-gram model\n",
    "ngrammake --method=witten_bell  news_small.char.cnt news_small.char.lm\n",
    "\n",
    "#info\n",
    "fstinfo news_small.char.lm\n",
    "\n",
    "#perplexity\n",
    "ngramperplexity news_small.char.lm news_small.char.far\n",
    "\n",
    "#shrink\n",
    "ngramshrink --method=relative_entropy --target_number_of_ngrams=10000 news_small.char.lm news_small.char.shrunk.lm\n",
    "\n",
    "#perplexity of shrunk\n",
    "ngramperplexity news_small.char.shrunk.lm news_small.char.far\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
